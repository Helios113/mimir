BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
results_new/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)
Saving results to absolute path: /nfs-share/mk2296/projects/llm_memorisation/mia/mimir/tmp_results/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)
LOG: cache_dir is nfs-share/mk2296/llm_memorisation/mia/mimir/cache
Using cache dir nfs-share/mk2296/llm_memorisation/mia/mimir/cache
Loading BASE model EleutherAI/gpt-neo-125m...
Loading mask filling model bert...
MOVING BASE MODEL TO GPU...Loading dataset the_pile...
Loading from HuggingFace!
Generating ngram_7_0.2 split: 0 examples [00:00, ? examples/s]Generating ngram_7_0.2 split: 74 examples [00:00, 728.52 examples/s]Generating ngram_7_0.2 split: 147 examples [00:00, 723.88 examples/s]Generating ngram_7_0.2 split: 224 examples [00:00, 741.57 examples/s]Generating ngram_7_0.2 split: 334 examples [00:00, 737.09 examples/s]Generating ngram_7_0.2 split: 413 examples [00:00, 749.80 examples/s]Generating ngram_7_0.2 split: 490 examples [00:00, 751.36 examples/s]Generating ngram_7_0.2 split: 599 examples [00:00, 736.66 examples/s]Generating ngram_7_0.2 split: 711 examples [00:00, 736.45 examples/s]Generating ngram_7_0.2 split: 786 examples [00:01, 736.19 examples/s]Generating ngram_7_0.2 split: 896 examples [00:01, 732.63 examples/s]Generating ngram_7_0.2 split: 972 examples [00:01, 737.94 examples/s]Generating ngram_7_0.2 split: 1000 examples [00:01, 592.64 examples/s]
Generating ngram_13_0.2 split: 0 examples [00:00, ? examples/s]Generating ngram_13_0.2 split: 74 examples [00:00, 725.19 examples/s]Generating ngram_13_0.2 split: 149 examples [00:00, 737.41 examples/s]Generating ngram_13_0.2 split: 225 examples [00:00, 743.23 examples/s]Generating ngram_13_0.2 split: 302 examples [00:00, 748.85 examples/s]Generating ngram_13_0.2 split: 378 examples [00:00, 747.62 examples/s]Generating ngram_13_0.2 split: 453 examples [00:00, 746.01 examples/s]Generating ngram_13_0.2 split: 529 examples [00:00, 749.44 examples/s]Generating ngram_13_0.2 split: 607 examples [00:00, 754.91 examples/s]Generating ngram_13_0.2 split: 686 examples [00:00, 759.73 examples/s]Generating ngram_13_0.2 split: 800 examples [00:01, 756.58 examples/s]Generating ngram_13_0.2 split: 879 examples [00:01, 762.64 examples/s]Generating ngram_13_0.2 split: 956 examples [00:01, 762.04 examples/s]Generating ngram_13_0.2 split: 1000 examples [00:01, 628.70 examples/s]
Generating ngram_13_0.8 split: 0 examples [00:00, ? examples/s]Generating ngram_13_0.8 split: 77 examples [00:00, 757.87 examples/s]Generating ngram_13_0.8 split: 193 examples [00:00, 761.17 examples/s]Generating ngram_13_0.8 split: 270 examples [00:00, 759.43 examples/s]Generating ngram_13_0.8 split: 380 examples [00:00, 745.16 examples/s]Generating ngram_13_0.8 split: 456 examples [00:00, 745.21 examples/s]Generating ngram_13_0.8 split: 534 examples [00:00, 750.48 examples/s]Generating ngram_13_0.8 split: 613 examples [00:00, 756.55 examples/s]Generating ngram_13_0.8 split: 691 examples [00:00, 759.96 examples/s]Generating ngram_13_0.8 split: 769 examples [00:01, 762.80 examples/s]Generating ngram_13_0.8 split: 849 examples [00:01, 770.45 examples/s]Generating ngram_13_0.8 split: 930 examples [00:01, 779.46 examples/s]Generating ngram_13_0.8 split: 1000 examples [00:01, 626.57 examples/s]
Traceback (most recent call last):
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 767, in <module>
    main(config)
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 532, in main
    data_obj_nonmem, data_nonmember = generate_data(
                                      ^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 431, in generate_data
    data = data_obj.load(
           ^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/mimir/data_utils.py", line 107, in load
    data = custom_datasets.load_cached(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/mimir/custom_datasets.py", line 75, in load_cached
    ds = datasets.load_dataset("iamgroot42/mimir", name=source, split=split, trust_remote_code=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/load.py", line 2166, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/builder.py", line 1126, in as_dataset
    datasets = map_nested(
               ^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/utils/py_utils.py", line 484, in map_nested
    mapped = function(data_struct)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/builder.py", line 1156, in _build_single_dataset
    ds = self._as_dataset(
         ^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/builder.py", line 1230, in _as_dataset
    dataset_kwargs = ArrowReader(cache_dir, self.info).read(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/arrow_reader.py", line 248, in read
    files = self.get_file_instructions(name, instructions, split_infos)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/arrow_reader.py", line 221, in get_file_instructions
    file_instructions = make_file_instructions(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/arrow_reader.py", line 130, in make_file_instructions
    absolute_instructions = instruction.to_absolute(name2len)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/arrow_reader.py", line 620, in to_absolute
    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/datasets/arrow_reader.py", line 437, in _rel_to_abs_instr
    raise ValueError(f'Unknown split "{split}". Should be one of {list(name2len)}.')
ValueError: Unknown split "none". Should be one of ['ngram_7_0.2', 'ngram_13_0.2', 'ngram_13_0.8'].
