BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
results_new/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)
Saving results to absolute path: /nfs-share/mk2296/projects/llm_memorisation/mia/mimir/tmp_results/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)
LOG: cache_dir is nfs-share/mk2296/llm_memorisation/mia/mimir/cache
Using cache dir nfs-share/mk2296/llm_memorisation/mia/mimir/cache
Loading BASE model EleutherAI/gpt-neo-125m...
Loading mask filling model bert...
MOVING BASE MODEL TO GPU...Loading dataset medpaca...
medpaca
['writing', 'english', 'german', 'pubmed', 'medpaca']
What is the priority during fasting and starvation in terms of supplying glucose and preserving protein, and which organs are prioritized for glucose supply? During fasting and starvation, the priority is to supply sufficient glucose to the brain and RBCs while preserving protein.
<generator object RegexpTokenizer.span_tokenize at 0x7f65e8a484f0>
Total number of samples: 1143
Average number of words: 130.93350831146105
Loading dataset medpaca...
medpaca
['writing', 'english', 'german', 'pubmed', 'medpaca']
What is the priority during fasting and starvation in terms of supplying glucose and preserving protein, and which organs are prioritized for glucose supply? During fasting and starvation, the priority is to supply sufficient glucose to the brain and RBCs while preserving protein.
<generator object RegexpTokenizer.span_tokenize at 0x7f65e8a486d0>
Total number of samples: 1143
Average number of words: 130.93350831146105
Generating samples:   0%|          | 0/21 [00:00<?, ?it/s]Generating samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 1199.76it/s]
NEW N_SAMPLES IS  1000
Writing raw data to tmp_results/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)/raw_data.json
Writing raw data to tmp_results/neo125_github_experiment_ne/EleutherAI_gpt-neo-125m/wikipedia_(en)/raw_data_lens.json
Computing criterion:   0%|          | 0/20 [00:00<?, ?it/s]
Generating neighbors:   0%|          | 0/1 [00:00<?, ?it/s][AGenerating neighbors:   0%|          | 0/1 [00:00<?, ?it/s]
Computing criterion:   0%|          | 0/20 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 767, in <module>
    main(config)
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 659, in main
    member_preds, member_samples = get_mia_scores(
                                   ^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/run.py", line 200, in get_mia_scores
    substr_neighbors = attacker.get_neighbors(
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/mimir/attacks/neighborhood.py", line 120, in get_neighbors
    neighbors = self.ref_model.generate_neighbors(documents, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/mimir/attacks/neighborhood.py", line 402, in generate_neighbors
    neighbors.extend(self.generate_neighbors_(text, **kwargs))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/projects/llm_memorisation/mia/mimir/mimir/attacks/neighborhood.py", line 430, in generate_neighbors_
    embeds = self.model.bert.embeddings(text_tokenized)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", line 211, in forward
    inputs_embeds = self.word_embeddings(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/nfs-share/mk2296/poetry/Cache/virtualenvs/mimir-Sp_lKhLC-py3.12/lib/python3.12/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
